# Objectives:

## Week1
- Understand the major trends driving the rise of deep learning.
Be able to explain how deep learning is applied to supervised learning.
Understand what are the major categories of models (such as CNNs and RNNs), and when they should be applied.
Be able to recognize the basics of when deep learning will (or will not) work well.

## Week2
- Build a logistic regression model, structured as a shallow neural network
Implement the main steps of an ML algorithm, including making predictions, derivative computation, and gradient descent.
Implement computationally efficient, highly vectorized, versions of models.
Understand how to compute derivatives for logistic regression, using a back propagation mindset.
Become familiar with Python and Numpy
Work with iPython Notebooks
Be able to implement vectorization across multiple training examples

## Week3
- Understand hidden units and hidden layers
Be able to apply a variety of activation functions in a neural network.
Build your first forward and backward propagation with a hidden layer
Apply random initialization to your neural network
Become fluent with Deep Learning notations and Neural Network Representations
Build and train a neural network with one hidden layer.

## Week4
- See deep neural networks as successive blocks put one after each other
Build and train a deep L-layer Neural Network
Analyze matrix and vector dimensions to check neural network implementations.
Understand how to use a cache to pass information from forward propagation to back propagation.
Understand the role of hyperparameters in deep learning

  ## Projects:
- Logistic Regression With Neural Networking Mindset
- Planar Data Classification 
 -Building Deep Neural Network: Step By Step
- Deep Neural Networking 

